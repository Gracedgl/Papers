\relax 
\citation{Curran:2013:AHC:2484920.2485183}
\citation{tumer-wolpert_jair02}
\citation{tumer-agogino_jaamas12}
\citation{AAMAS12-agmon}
\citation{5509316}
\citation{Colby:2012:SFF:2343576.2343637}
\citation{Proper:2012:MDR:2343896.2344025}
\citation{tumer-holmesparker_ala12}
\citation{Curran:2013:AHC:2484920.2485183}
\citation{BarProblem}
\citation{Agogino:2009:EEM:1570256.1570258,Curran:2013:AHC:2484920.2485183,Rios}
\citation{faa05}
\citation{Curran:2013:AHC:2484920.2485183}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\citation{716791}
\citation{Sun98someexperiments}
\citation{Dayan93feudalreinforcement}
\citation{Reddy_learninggoal-decomposition}
\citation{Zhang:2010:SCD:1838206.1838304}
\citation{Junges:2008:EPD:1402298.1402308,Modi:2005:AAD:1120120.1120127}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{3}}
\newlabel{sec:BACKGROUND}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{Agent Partitioning}{3}}
\citation{Zhang:2010:SCD:1838206.1838304}
\citation{Junges:2008:EPD:1402298.1402308,Modi:2005:AAD:1120120.1120127}
\citation{tumer-wolpert_jair02}
\citation{tumer-agogino_jaamas12}
\citation{AAMAS12-agmon}
\citation{5509316}
\citation{Colby:2012:SFF:2343576.2343637}
\citation{Hardin}
\citation{tumer-wolpert_jair02}
\@writefile{toc}{\contentsline {subsection}{Difference Rewards}{4}}
\newlabel{sec:Difference Reward}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{Clustering algorithms}{4}}
\citation{Jain:2010:DCY:1755267.1755654}
\citation{Zhao:2002:EHC:584792.584877}
\citation{Bottegoni15072006}
\citation{Manning:2008:IIR:1394399,Agglomerative}
\citation{Manning:2008:IIR:1394399}
\@writefile{toc}{\contentsline {section}{\numberline {3}RUBI}{5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Hierarchical Agglomerative Clustering}}{6}}
\@writefile{toc}{\contentsline {subsection}{The RUBI Algorithm}{6}}
\newlabel{eq:RUBI Update}{{2}{6}}
\newlabel{alg:RUBI}{{3}{7}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Reward/Utility-Based Impact Algorithm}}{7}}
\@writefile{toc}{\contentsline {subsection}{Impact Calculation}{7}}
\citation{Taylor:2009:TLR:1577069.1755839}
\citation{6378284}
\citation{BarProblem}
\citation{Watkins92q-learning}
\citation{BarProblem}
\@writefile{toc}{\contentsline {subsection}{Simulation}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Validation}{8}}
\@writefile{toc}{\contentsline {subsection}{Heterogeneous Bar Problem}{8}}
\newlabel{eq:BarProblem-Local}{{3}{8}}
\citation{Curran:2013:AHC:2484920.2485183}
\citation{Agogino:2009:EEM:1570256.1570258}
\citation{Rios}
\newlabel{eq:BarProblem-Global}{{4}{9}}
\@writefile{toc}{\contentsline {subsection}{Air Traffic Flow Management Problem}{9}}
\citation{Agogino:2009:EEM:1570256.1570258}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Learning cycle of agents in the Air Traffic Flow Management Problem.}}{10}}
\newlabel{LearningCycle}{{1}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Agent Definition}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Reward Structures}{10}}
\newlabel{eq:Global}{{5}{10}}
\newlabel{eq:RUBI ATFMP-L}{{8}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Computational Complexity}{11}}
\newlabel{sec:Complexity}{{4}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Optimization with Domain-Based Partitioning}{11}}
\newlabel{sec:Domain-Based}{{5}{11}}
\@writefile{toc}{\contentsline {subsection}{Domain-Based Partitioning Performance in the ATFMP}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The highest level of partitioning for the system-level reward (G) is displayed here and compared with a single partition and the greedy scheduler. The learned policies initially perform similarly to the greedy scheduler because the policy for each agent is initialized with zero delay actions. The system-level reward performed worse with fewer partitions, but still better than a single partition. Even though partitioning performed better than a single partition, the system-level reward could not come close to beating the greedy scheduler. Using this learning approach, the system-level reward performance could never become better than the greedy scheduler.}}{13}}
\newlabel{ClusterRewardsGreedyG}{{2}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A closer look at the difference reward performance using the smaller number of partitions shows a 37\% improvement over the greedy scheduling solution.}}{13}}
\newlabel{ATFMPOldDvsGreedy}{{3}{13}}
\citation{BarProblem}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces With the greater number of partitions, the learning performance decreases and speed increases. Note that the outlier is a artifact of the greedy scheduler discussed in this section.}}{14}}
\newlabel{ATFMPOldTable}{{1}{14}}
\@writefile{toc}{\contentsline {subsection}{Partition Comparisons with Domain-Based Partitioning}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Optimization with RUBI}{14}}
\newlabel{sec:RUBI Results}{{6}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces As the number of partitions decrease, the agents receive more information about the environment, leading to better performance at the cost of speed. }}{15}}
\newlabel{BarProblemNewPartitions}{{4}{15}}
\@writefile{toc}{\contentsline {subsection}{RUBI Performance in the Bar Problem}{15}}
\@writefile{toc}{\contentsline {subsection}{RUBI Performance in the ATFMP}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Like in Figure 4\hbox {}, as the number of partitions decreases, the agents receive more information about the environment. This leads to better performance at the cost of speed. The HAC algorithm converged to 61 independent partitions.}}{16}}
\newlabel{ATFMPComparisonNoScale}{{5}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Comparison Between RUBI and Domain-Based Partitioning}{16}}
\newlabel{sec:Comparison}{{7}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The final performance of RUBI partitions compared to domain-based partitions. In highly-partitioned cases, domain-based partitions perform better than RUBI, with RUBI performing better with a smaller number of partitions.}}{17}}
\newlabel{FinalOldvsFinalNew}{{6}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces In highly-partitioned cases, domain-based partitioning has a larger average size of the top 5\% of partitions, leading to a higher initial performance (Figure 6). With a smaller number of partitions, RUBI partitioning had a larger size of partitions. Note that when all partitions are reward independent, domain-based partitioning had only a few large partitions. RUBI partitioning on the other hand included a much smaller average size, and many more partitions. Smaller and more numerous partitions lead to faster simulations (Section 4\hbox {}).}}{17}}
\newlabel{OldvsNewAvgSize}{{7}{17}}
\citation{Junges:2008:EPD:1402298.1402308,Modi:2005:AAD:1120120.1120127,Zhang:2010:SCD:1838206.1838304}
\citation{Curran:2013:AHC:2484920.2485183,tumer-holmesparker_ala12,Proper:2012:MDR:2343896.2344025}
\citation{Proper:2012:MDR:2343896.2344025}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces When comparing individual partition size averages to performance, RUBI partitions perform much better than domain specific partitions with respect to average partition size and final performance.}}{18}}
\newlabel{ATFMPPerformancevsAvgSize}{{8}{18}}
\bibstyle{spbasic}
\bibdata{thesis}
\bibcite{AAMAS12-agmon}{{1}{2012}{{Agmon and Stone}}{{}}}
\bibcite{Agogino:2009:EEM:1570256.1570258}{{2}{2009}{{Agogino}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{19}}
\newlabel{sec:CONCLUSION}{{8}{19}}
\bibcite{tumer-agogino_jaamas12}{{3}{2012}{{Agogino and Tumer}}{{}}}
\bibcite{BarProblem}{{4}{1994}{{Arthur}}{{}}}
\bibcite{Bottegoni15072006}{{5}{2006}{{Bottegoni et~al}}{{Bottegoni, Rocchia, Recanatini, and Cavalli}}}
\bibcite{Colby:2012:SFF:2343576.2343637}{{6}{2012}{{Colby and Tumer}}{{}}}
\bibcite{Curran:2013:AHC:2484920.2485183}{{7}{2013}{{Curran et~al}}{{Curran, Agogino, and Tumer}}}
\bibcite{Agglomerative}{{8}{1984}{{Day and Edelsbrunner}}{{}}}
\bibcite{Dayan93feudalreinforcement}{{9}{1993}{{Dayan and Hinton}}{{}}}
\bibcite{Hardin}{{10}{December 1968}{{Hardin}}{{}}}
\bibcite{Jain:2010:DCY:1755267.1755654}{{11}{2010}{{Jain}}{{}}}
\bibcite{716791}{{12}{1993}{{Jordan and Jacobs}}{{}}}
\bibcite{Junges:2008:EPD:1402298.1402308}{{13}{2008}{{Junges and Bazzan}}{{}}}
\bibcite{5509316}{{14}{2010}{{Kaminka et~al}}{{Kaminka, Erusalimchik, and Kraus}}}
\bibcite{Manning:2008:IIR:1394399}{{15}{2008}{{Manning et~al}}{{Manning, Raghavan, and Sch\"{u}tze}}}
\bibcite{Modi:2005:AAD:1120120.1120127}{{16}{2005}{{Modi et~al}}{{Modi, Shen, Tambe, and Yokoo}}}
\bibcite{faa05}{{17}{2011}{{OPSNET}}{{}}}
\bibcite{tumer-holmesparker_ala12}{{18}{2012}{{Parker and Tumer}}{{}}}
\bibcite{Proper:2012:MDR:2343896.2344025}{{19}{2012}{{Proper and Tumer}}{{}}}
\bibcite{Reddy_learninggoal-decomposition}{{20}{1997}{{Reddy and Tadepalli}}{{}}}
\bibcite{Rios}{{21}{2009}{{Rios and Lohn}}{{}}}
\bibcite{Sun98someexperiments}{{22}{1998}{{Sun and Peterson}}{{}}}
\bibcite{Taylor:2009:TLR:1577069.1755839}{{23}{2009}{{Taylor and Stone}}{{}}}
\bibcite{Watkins92q-learning}{{24}{1992}{{Watkins and Dayan}}{{}}}
\bibcite{tumer-wolpert_jair02}{{25}{2002}{{Wolpert and Tumer}}{{}}}
\bibcite{6378284}{{26}{2012}{{Yu et~al}}{{Yu, Dang, and Yang}}}
\bibcite{Zhang:2010:SCD:1838206.1838304}{{27}{2010}{{Zhang et~al}}{{Zhang, Lesser, and Abdallah}}}
\bibcite{Zhao:2002:EHC:584792.584877}{{28}{2002}{{Zhao and Karypis}}{{}}}

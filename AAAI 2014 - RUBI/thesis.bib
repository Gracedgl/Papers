% This file was created with JabRef 2.8.1.
% Encoding: Cp1252

@inproceedings{DBLP:dblp_conf/gecco/CurranAT13,
   author              = {William J. Curran and 
                          Adrian K. Agogino and 
                          Kagan Tumer},
   title               = {Partitioning agents and shaping their evaluation functions in air traffic problems with hard constraints.},
   booktitle           = {GECCO (Companion)},
   year                = {2013},
   pages               = {183-184},
   ee                  = {http://doi.acm.org/10.1145/2464576.2464666},
   crossref            = {2013},
}



@incollection{tumer-holmesparker_ala12,
        author = {C. Holmes Parker and K. Tumer},
        title = {Combining Difference Rewards and Hierarchies for Scaling to Large Multiagent System},
        booktitle = {AAMAS-2012 Workshop on Adaptive and Learning Agents},
	month = {June},
	address = {Valencia, Spain},
	editors = {E. Howley and P. Vrancx and M. Knudson},
	abstract={Coordinating the actions of agents in multiagent systems presents a challenging problem, especially as the size of the system is increased and predicting the agent interactions becomes difficult. Many approaches to improving coordination within multiagent systems have been developed including organizational structures, shaped rewards, coordination graphs, heuristic methods, and learning automata. However, each of these approaches still have limitations with respect to scalability. The goal of this paper is to combine two such coordination mechanisms (difference rewards and hierarchical organization) to improve scalability. We combine difference rewards and hierarchical organizations in the Defect Combination Problem (DCP) with 10,000 sensing agents. We show that combining these techniques results in significantly improved performance and robustness compared to either approach individually. In particular, we show that combining hierarchical organization with difference rewards can improve both coordination and scalability by decreasing information overhead, structuring agent-to-agent connectivity and control flow, and improving the individual decision making capabilities of agents.},
	bib2html_pubtype = {Workshop/Symposium Papers},
	bib2html_rescat = {Multiagent Systems, Reinforcement Learning},
        year = {2012}
}


@inproceedings{Proper:2012:MDR:2343896.2344025,
 author = {Proper, Scott and Tumer, Kagan},
 title = {Modeling difference rewards for multiagent learning},
 booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 3},
 year = {2012},
 isbn = {0-9817381-3-3, 978-0-9817381-3-0},
 location = {Valencia, Spain},
 keywords = {air traffic control, function approximation, multiagent coordination, neural networks, reward shaping, scaling}
} 

@inproceedings{Agogino:2012:ELS:2330163.2330306,
 author = {Agogino, Adrian and HolmesParker, Chris and Tumer, Kagan},
 title = {Evolving large scale UAV communication system},
 booktitle = {Proceedings of the fourteenth international conference on Genetic and evolutionary computation conference},
 year = {2012},
 isbn = {978-1-4503-1177-9},
 location = {Philadelphia, Pennsylvania, USA}
} 


@inproceedings{Colby:2012:SFF:2343576.2343637,
 author = {Colby, Mitchell and Tumer, Kagan},
 title = {Shaping fitness functions for coevolving cooperative multiagent systems},
 booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems},
 year = {2012},
 isbn = {0-9817381-1-7, 978-0-9817381-1-6},
 location = {Valencia, Spain},
 keywords = {co-evolution, multiagent learning}
} 

@inproceedings{Curran:2013:AHC:2484920.2485183,
 author = {Curran, William J. and Agogino, Adrian and Tumer, Kagan},
 title = {Addressing hard constraints in the air traffic problem through partitioning and difference rewards},
 booktitle = {Proceedings of the 2013 international conference on Autonomous agents and multi-agent systems},
 year = {2013},
 isbn = {978-1-4503-1993-5},
 location = {St. Paul, MN, USA},
}

@article{journals/advcs/AgoginoT09,
  added-at = {2010-07-21T15:53:55.000+0200},
  author = {Agogino, Adrian K. and Tumer, Kagan},
  biburl = {http://www.bibsonomy.org/bibtex/288edd6d445ce5bb87903dbe863cbf775/dblp},
  date = {2010-06-15},
  ee = {http://dx.doi.org/10.1142/S0219525909002283},
  interhash = {9d1c54de7986e395cac0362a42d528b4},
  intrahash = {88edd6d445ce5bb87903dbe863cbf775},
  journal = {Advances in Complex Systems},
  keywords = {dblp},
  number = {4-5},
  pages = {493-512},
  timestamp = {2010-07-21T15:53:55.000+0200},
  title = {Learning Indirect Actions in Complex Domains: Action Suggestions for Air Traffic Control.},
  url = {http://dblp.uni-trier.de/db/journals/advcs/advcs12.html#AgoginoT09},
  }
@inproceedings{Agogino:2009:EEM:1570256.1570258,
 author = {Agogino, Adrian},
 title = {Evaluating evolution and monte carlo for controlling air traffic flow},
 booktitle = {Proceedings of the 11th Annual Conference Companion on Genetic and Evolutionary Computation Conference: Late Breaking Papers},
 year = {2009}
} 

@INPROCEEDINGS{Zhang95areinforcement,
    author = {Wei Zhang and Thomas G. Dietterich},
    title = {A Reinforcement Learning Approach to Job-shop Scheduling},
    booktitle = {In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence},
    year = {1995},
    pages = {1114--1120},
    publisher = {Morgan Kaufmann}
}


@INPROCEEDINGS{Dayan93feudalreinforcement,
    author = {Peter Dayan and Geoffrey E. Hinton},
    title = {Feudal Reinforcement Learning},
    booktitle = {Advances in Neural Information Processing Systems 5},
    year = {1993},
    pages = {271--278},
    publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{Reddy_learninggoal-decomposition,
    author = {Chandra Reddy and Prasad Tadepalli},
    title = {Learning Goal-Decomposition Rules using Exercises},
    booktitle = {In Proceedings of the 14th International Conference on Machine Learning},
    year = {},
    pages = {278--286},
    publisher = {Morgan Kaufmann}
}

@ARTICLE{Sun98someexperiments,
    author = {Ron Sun and Todd Peterson},
    title = {Some Experiments with a Hybrid Model for Learning Sequential Decision Making},
    journal = {Information Sciences},
    year = {1998},
    volume = {111},
    pages = {83--107}
}

@INPROCEEDINGS{716791, 
author={Jordan, M.I. and Jacobs, Robert A.}, 
booktitle={Neural Networks, 1993. IJCNN '93-Nagoya. Proceedings of 1993 International Joint Conference on}, 
title={Hierarchical mixtures of experts and the EM algorithm}, 
year={1993}, 
volume={2}, 
pages={1339-1344 vol.2}, 
keywords={learning (artificial intelligence);maximum likelihood estimation;neural net architecture;expectation-maximization algorithm;experts;generalized linear models;hierarchical mixture model;maximum likelihood problem;neural nets;robot dynamics;statistical model;supervised learning;tree-structured architecture;Biological neural networks;Jacobian matrices;Machine learning algorithms;Mars;Orbital robotics;Partitioning algorithms;Psychology;Supervised learning;Surface fitting;Vectors}, 
doi={10.1109/IJCNN.1993.716791},}

@article{Jain:2010:DCY:1755267.1755654,
 author = {Jain, Anil K.},
 title = {Data clustering: 50 years beyond K-means},
 journal = {Pattern Recogn. Lett.},
 issue_date = {June, 2010},
 volume = {31},
 number = {8},
 month = jun,
 year = {2010},
 issn = {0167-8655},
 pages = {651--666},
 numpages = {16},
 url = {http://dx.doi.org/10.1016/j.patrec.2009.09.011},
 doi = {10.1016/j.patrec.2009.09.011},
 acmid = {1755654},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {Data clustering, Historical developments, King-Sun Fu prize, Perspectives on clustering, User's dilemma}
} 


@book{tuyls2006learning,
  title={Learning and Adaption in Multi-Agent Systems: First International Workshop, LAMAS 2005, Utrecht, The Netherlands, July 25, 2005, Revised Selected Papers},
  author={Tuyls, K.},
  isbn={9783540330530},
  lccn={2006923098},
  series={Lecture Notes in Computer Science / Lecture Notes in Artificial Intelligence},
  url={http://books.google.com/books?id=\_QGT5kUA\_u0C},
  year={2006},
  publisher={Springer}
}



@article{Zhang-406,
  author    = "Haizheng Zhang and Victor Lesser",
  title     = "{Forming and Searching Content-Based Hierarchical
               Agent Clusters In Distributed Information
               Retrieval Systems}",
  journal   = "Web Intelligence and Agent Systems",
  volume    = "4",
  number    = "4",
  publisher = "IOS Press",
  pages     = "353-370",
  month     = "November",
  year      = "2006",
  url       = "http://mas.cs.umass.edu/paper/406",
}


@inproceedings{tumer-colby_gecco11,
        author = {M. Colby and E. Nasroullahi and K. Tumer},
        title = {Optimizing Ballast Design of Wave Energy Converters Using Evolutionary Algorithms},
        booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
	month = {July},
	address = {Dublin, Ireland},
	pages = {1739-1746},
	abstract={Wave energy converters promise to be a viable alternative to current electrical generation methods. However, these generators must become more efficient before wide-scale industrial use can become cost-effective. The efficiency of these devices is primarily dependent upon their geometry and ballast configuration which are both difficult to evaluate, due to slow computation time and high computation cost of current models.
In this paper, we use evolutionary algorithms to optimize the ballast geometry of a wave energy generator using a two step process. First, we generate  a  function approximator (neural network) to predict wave energy converter power output with respect to key geometric design variables. This is a critical step as the computation time of using a full model (e.g., AQWA) to predict energy output prohibits the use of an evolutionary algorithm for design optimization. The function approximator  reduced the computation time by over 99\% while having an average error of only 3.5\%.  The evolutionary algorithm then optimized the weight distribution of a wave energy generator, resulting in an  84\% improvement in power output over a ballast-free wave energy converter.
},
	bib2html_pubtype = {Refereed Conference Papers},
	bib2html_rescat = {Evolutionary Algorithms},
        year = {2011}
}


@inproceedings{holmes-aamas,
        author = {C. HolmesParker and A. Agogino and K. Tumer.},
        title = {CLEAN Rewards for Improving Multiagent Coordination in the Presence of Exploration},
        booktitle = {Proceedings of the Twelfth International Conference on Autonomous Agents and Multiagent Systems},
	month = {June},
	year = {2013},
}


@MISC{Nwana96co-ordinationin,
    author = {H S Nwana and L Lee and N R Jennings},
    title = {Co-Ordination in Software Agent Systems},
    year = {1996}
}

@ARTICLE{Dietterich00hierarchicalreinforcement,
    author = {Thomas G. Dietterich},
    title = {Hierarchical Reinforcement Learning with the {MAXQ} Value Function Decomposition},
    journal = {Journal of Artificial Intelligence Research},
    year = {2000},
    volume = {13},
    pages = {227--303}
}

@ARTICLE{788664, 
author={Bao-Liang Lu and Ito, M.}, 
journal={Neural Networks, IEEE Transactions on}, title={Task decomposition and module combination based on class relations: a modular neural network for pattern classification}, 
year={1999}, 
volume={10}, 
number={5}, 
pages={1244-1256}, 
keywords={divide and conquer methods;learning (artificial intelligence);neural nets;pattern classification;class relations;combination principles;modular neural network;module combination;task decomposition;training data;Biological neural networks;Chemicals;Computer architecture;Guidelines;Indium tin oxide;Laboratories;Large-scale systems;Neural networks;Pattern classification;Training data}, 
doi={10.1109/72.788664}, 
ISSN={1045-9227},}

@INPROCEEDINGS{399902, 
author={Tzafestas, E.S.}, 
booktitle={Systems, Man, and Cybernetics, 1994. Humans, Information and Technology., 1994 IEEE International Conference on}, title={Agentifying the process: task-based or robot-based decomposition?}, 
year={1994}, 
volume={1}, 
pages={582-587 vol.1}, 
keywords={cooperative systems;industrial control;industrial robots;adaptivity;cellular manufacturing;control localisation;flexibility;interaction minimisation;knowledge decoupling;multi-agent systems;robot-based decomposition;system scaling substrate;task-based decomposition;Artificial intelligence;Cellular manufacturing;Fault tolerant systems;Job shop scheduling;Manufacturing systems;Modems;Multiagent systems;Production systems;Robots;Uncertainty}, 
doi={10.1109/ICSMC.1994.399902},}

@inproceedings{Doucette:2012:HTD:2330163.2330178,
 author = {Doucette, John A. and Lichodzijewski, Peter and Heywood, Malcolm I.},
 title = {Hierarchical task decomposition through symbiosis in reinforcement learning},
 booktitle = {Proceedings of the fourteenth international conference on Genetic and evolutionary computation conference},
 series = {GECCO '12},
 year = {2012},
 isbn = {978-1-4503-1177-9},
 location = {Philadelphia, Pennsylvania, USA},
 pages = {97--104},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2330163.2330178},
 doi = {10.1145/2330163.2330178},
 acmid = {2330178},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {genetic programming, meta actions, reinforcement learning, symbiosis, task decomposition},
} 

@INPROCEEDINGS{4708962, 
author={Lasheng Yu and Fei Hong and PengRen Wang and Yang Xu and Yong Liu}, 
booktitle={Young Computer Scientists, 2008. ICYCS 2008. The 9th International Conference for}, title={Influence Graph based Task Decomposition and State Abstraction in Reinforcement Learning}, 
year={2008}, 
pages={136-141}, 
keywords={Bayes methods;dynamic programming;graph theory;learning (artificial intelligence);dynamic Bayesian network model;dynamic programming;influence graph;reinforcement learning;state abstraction;state variable influence algorithm;task decomposition;Acceleration;Bayesian methods;Dynamic programming;Function approximation;Information science;Learning;Manufacturing industries;Mice;Service robots;Stochastic processes;SVI algorithm;dynamic Bayesian network;influence graph;reinforcement learning;task decomposition}, 
doi={10.1109/ICYCS.2008.34},}

@INPROCEEDINGS{Guttmann_makingallocations,
    author = {Christian Guttmann},
    title = {Making allocations collectively: Iterative group decision making under uncertainty},
    booktitle = {Proceedings of the sixth German Conference on Multi-Agent system TEchnologieS (MATES), volume 5244 of Lecture},
    year = {}
}

@inproceedings{Guestrin:2002:CRL:645531.757784,
 author = {He, L. and Ioerger, T.R},
 title = {A quantitative model of capabilities in multi-agent systems},
 booktitle = {Proceedings of the International Conference on Artiﬁcial Intelligence},
 series = {IC-AI '03},
 year = {2003},
 pages = {730--736},
}

@ARTICLE{Tambe97towardsflexible,
    author = {Milind Tambe},
    title = {Towards flexible teamwork},
    journal = {Journal of Artificial Intelligence Research},
    year = {1997},
    volume = {7},
    pages = {83--124}
}

@inproceedings{Guestrin:2002:CRL:645531.757784,
 author = {Guestrin, Carlos and Lagoudakis, Michail G. and Parr, Ronald},
 title = {Coordinated Reinforcement Learning},
 booktitle = {Proceedings of the Nineteenth International Conference on Machine Learning},
 series = {ICML '02},
 year = {2002},
 isbn = {1-55860-873-7},
 pages = {227--234},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645531.757784},
 acmid = {757784}
} 

@inproceedings{Knudson:2010:RCA:1838206.1838422,
 author = {Knudson, Matt and Tumer, Kagan},
 title = {Robot coordination with ad-hoc team formation},
 booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1 - Volume 1},
 series = {AAMAS '10},
 year = {2010},
 isbn = {978-0-9826571-1-9},
 location = {Toronto, Canada},
 pages = {1441--1442},
 numpages = {2},
 url = {http://dl.acm.org/citation.cfm?id=1838206.1838422},
 acmid = {1838422},
 keywords = {agent cooperation, learning (multiagent), teamwork}
} 


@INPROCEEDINGS{6378284, 
author={Litao Yu and Yanzhong Dang and Guangfei Yang}, 
booktitle={Systems, Man, and Cybernetics (SMC), 2012 IEEE International Conference on}, title={Transfer clustering via constraints generated from topics}, 
year={2012}, 
keywords={data mining;data structures;lab-on-a-chip;learning (artificial intelligence);natural language processing;pattern clustering;TCTC;data clustering;data mining;gene-microarray analysis;natural language processing;semisupervised clustering algorithm;topic generated constraints;topic-constraint transfer clustering;transfer clustering technique;unlabeled data;unsupervised transfer learning;Algorithm design and analysis;Bridges;Clustering algorithms;Data mining;Entropy;Equations;Mathematical model;Unsupervised transfer learning;semi-supervised clustering;topic transfer}, 
doi={10.1109/ICSMC.2012.6378284},}


@article{Bottegoni15072006,
author = {Bottegoni, Giovanni and Rocchia, Walter and Recanatini, Maurizio and Cavalli, Andrea}, 
title = {AClAP, Autonomous hierarchical agglomerative Cluster Analysis based protocol to partition conformational datasets},
volume = {22}, 
number = {14}, 
pages = {e58-e65}, 
year = {2006}, 
doi = {10.1093/bioinformatics/btl212}, 
abstract ={Motivation: Sampling the conformational space is a fundamental step for both ligand- and structure-based drug design. However, the rational organization of different molecular conformations still remains a challenge. In fact, for drug design applications, the sampling process provides a redundant conformation set whose thorough analysis can be intensive, or even prohibitive. We propose a statistical approach based on cluster analysis aimed at rationalizing the output of methods such as Monte Carlo, genetic, and reconstruction algorithms. Although some software already implements clustering procedures, at present, a universally accepted protocol is still missing.Results: We integrated hierarchical agglomerative cluster analysis with a clusterability assessment method and a user independent cutting rule, to form a global protocol that we implemented in a MATLAB metalanguage program (AClAP). We tested it on the conformational space of a quite diverse set of drugs generated via Metropolis Monte Carlo simulation, and on the poses we obtained by reiterated docking runs performed by four widespread programs. In our tests, AClAP proved to remarkably reduce the dimensionality of the original datasets at a negligible computational cost. Moreover, when applied to the outcomes of many docking programs together, it was able to point to the crystallographic pose.Availability: AClAP is available at the “AClAP” section of the website http://www.scfarm.unibo.it.Contact: E-mail: andrea.cavalli@unibo.it.Supplementary Information: The complete series of AClAP results is available in the “services” section of the website http://www.scfarm.unibo.it.}, 
URL = {http://bioinformatics.oxfordjournals.org/content/22/14/e58.abstract}, 
eprint = {http://bioinformatics.oxfordjournals.org/content/22/14/e58.full.pdf+html}, 
journal = {Bioinformatics} 
}



@inproceedings{Zhao:2002:EHC:584792.584877,
 author = {Zhao, Ying and Karypis, George},
 title = {Evaluation of hierarchical clustering algorithms for document datasets},
 booktitle = {Proceedings of the eleventh international conference on Information and knowledge management},
 series = {CIKM '02},
 year = {2002},
 isbn = {1-58113-492-4},
 location = {McLean, Virginia, USA},
 pages = {515--524},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/584792.584877},
 doi = {10.1145/584792.584877},
 acmid = {584877},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {agglomerative clustering, hierarchical clustering, partitional clustering}
} 

@BOOK{Sutton98reinforcementlearning,
    author = {Richard S. Sutton and Andrew G. Barto},
    title = {Reinforcement Learning I: Introduction},
    year = {1998}
}

@inproceedings{BarProblem,
    author = {Brian W. Arthur},
    title = {Inductive Reasoning and Bounded Rationality},
    booktitle = {American Economic Review (Papers and Proceedings)},
    year = {1994},
 	volume = {84},
 	pages = {406--411}  
}


@inproceedings{Bilimoria,
    author = {Karl D. Bilimoria},
    title = {A Geometric Optimization Approach to Aircraft Conflict Resolution},
    booktitle = {AIAA Guidance, Navigation, and Control Conference and Exhibit},
    address = {Keystone, CO},
}


@inproceedings{McNally,
    author = {David McNally and Chester Gong},
    title = {Concept and Laboratory Analysis of
    Trajectory-Based Automation for Separation Assurance},
    booktitle = {AIAA Guidance,
	Navigation and Control Conference and Exhibit},
    address = {Keystone, CO},
}

@inproceedings{Mueller_analysisof,
    author = {Eric R. Mueller and Gano B. Chatterji},
    title = {ANALYSIS OF AIRCRAFT ARRIVAL AND DEPARTURE DELAY CHARACTERISTICS},
    booktitle = {AIAA Aircraft Technology, Integration
    and Operations (ATIO) Conference},
    address = {Los Angeles, CA},

}

@article{Bertsimas:1998:ATF:767667.768027,
 author = {Bertsimas, Dimitris and Patterson, Sarah Stock},
 title = {The Air Traffic Flow Management Problem with Enroute Capacities},
 journal = {Oper. Res.},
 issue_date = {March 1998},
 volume = {46},
 number = {3},
 month = mar,
 year = {1998},
 issn = {0030-364X},
 pages = {406--422},
 numpages = {17},
 url = {http://dx.doi.org/10.1287/opre.46.3.406},
 doi = {10.1287/opre.46.3.406},
 acmid = {768027},
 publisher = {INFORMS},
 address = {Institute for Operations Research and the Management Sciences (INFORMS), Linthicum, Maryland, USA},
 keywords = {Programming, Transportation, air traffic, applications, integer}
} 

@INPROCEEDINGS{Sislak:2008:AMA:1402744.1402755,
  author = {\v{S}i\v{s}l\'{a}k, David and Volf, P\v{r}emysl and Kop\v{r}iva,
	\v{S}t\v{e}p\'{a}n and P\v{e}chou\v{c}ek, Michal},
  title = {AGENTFLY: a multi-agent airspace test-bed},
  booktitle = {Proceedings of the 7th international joint conference on Autonomous
	agents and multiagent systems: demo papers},
  year = {2008},
  series = {AAMAS '08},
  pages = {1665--1666},
  address = {Richland, SC},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  acmid = {1402755},
  keywords = {agent-based collision avoidance, autonomous aircrafts, multi-agent
	simulation},
  location = {Estoril, Portugal},
  numpages = {2},
  url = {http://dl.acm.org/citation.cfm?id=1402744.1402755}
}

@INPROCEEDINGS{AAMAS12-agmon,
  author = {Noa Agmon and Peter Stone},
  title = {Leading Ad Hoc Agents in Joint Action Settings with Multiple Teammates},
  booktitle = {Proc. of 11th Int. Conf. on Autonomous Agents and Multiagent Systems
	(AAMAS 2012)},
  year = {2012},
  month = {June},
  abstract = { The growing use of autonomous agents in practice may require agents
	to cooperate as a team in situations where they have limited prior
	knowledge about one another, cannot communicate directly, or do not
	share the same world models. These situations raise the need to design
	ad hoc team members, i.e., agents that will be able to cooperate
	without coordination in order to reach an optimal team behavior.
	This paper considers the problem of leading N-agent teams by an agent
	toward their optimal joint utility, where the agents compute their
	next actions based only on their most recent observations of their
	teammatesâ€™ actions. We show that compared to previous results in
	two-agent teams, in larger teams the agent might not be able to lead
	the team to the action with maximal joint utility, thus its optimal
	strategy is to lead the team to the best possible reachable cycle
	of joint actions. We describe a graphical model of the problem and
	a polynomial time algorithm for solving it. We then consider other
	variations of the problem, including leading teams of agents where
	they base their actions on longer history of past observations, leading
	a team by more than one ad hoc agent, and leading a teammate while
	the ad hoc agent is uncertain of its behavior. },
  location = {Valencia, Spain}
}

@ARTICLE{tumer-agogino_jaamas12,
  author = {A. K. Agogino and K. Tumer},
  title = {A Multiagent Approach to Managing Air Traffic Flow},
  journal = {Autonomous Agents and MultiAgent Systems},
  year = {2012},
  volume = {24},
  pages = {1-25},
  abstract = {Intelligent air traffic flow management is one of the fundamental
	challenges facing the Federal Aviation Administration (FAA) today.
	FAA estimates put weather, routing decisions and airport condition
	induced delays at 1,682,700 hours in 2007, resulting in a staggering
	economic loss of over $41 Billion. New solutions to the flow management
	are needed to accommodate the threefold increase in air traffic anticipated
	over the next two decades. Indeed, this is a complex problem where
	the interactions of changing conditions (e.g., weather), conflicting
	priorities (e.g., different airlines), limited resources (e.g., air
	traffic controllers) and heavy volume (e.g., over 40,000 flights
	over the US airspace) demand an adaptive and robust solution. In
	this paper we explore a multiagent algorithm where agents use reinforcement
	learning to reduce congestion through local actions. Each agent is
	associated with a fix (a specific location in 2D space) and has one
	of three actions: setting separation between airplanes, ordering
	ground delays or performing reroutes. We simulate air traffic using
	FACET which is an air traffic flow simulator developed at NASA and
	used extensively by the FAA and industry. Our FACET simulations on
	both artificial and real historical data from the Chicago and New
	York airspaces show that agents receiving personalized rewards reduce
	congestion by up to 80\% over agents receiving a global reward and
	by up to 90\% over a current industry approach (Monte Carlo estimation).},
  bib2html_pubtype = {Journal Articles},
  bib2html_rescat = {Air Traffic Control, Multiagent Systems, Traffic and Transportation}
}

@ARTICLE{tumer-agogino_jaamas08,
  author = {A. K. Agogino and K. Tumer},
  title = {Analyzing and Visualizing Multiagent Rewards in Dynamic and Stochastic
	Environments},
  journal = {Journal of Autonomous Agents and Multi-Agent Systems},
  year = {2008},
  volume = {17},
  pages = {320-338},
  number = {2},
  abstract = { The ability to analyze the effectiveness of agent reward structures
	is critical to the successful design of multiagent learning algorithms.
	Though final system performance is the best indicator of the suitability
	of a given reward structure, it is often preferable to analyze the
	reward properties that lead to good system behavior (i.e., properties
	promoting coordination among the agents and providing agents with
	strong signal to noise ratios). This step is particularly helpful
	in continuous, dynamic, stochastic domains ill-suited to simple table
	backup schemes commonly used in TD(\lambda)/Q-learning where the
	effectiveness of the reward structure is difficult to distinguish
	from the effectiveness of the chosen learning algorithm. In this
	paper, we present a new reward evaluation method that provides a
	visualization of the tradeoff between the level of coordination among
	the agents and the difficulty of the learning problem each agent
	faces. This method is independent of the learning algorithm and is
	only a function of the problem domain and the agents' reward structure.
	We use this reward property visualization method to determine an
	effective reward without performing extensive simulations. We then
	test this method in both a static and a dynamic multi-rover learning
	domain where the agents have continuous state spaces and take noisy
	actions (e.g., the agents' movement decisions are not always carried
	out properly). Our results show that in the more difficult dynamic
	domain, the reward efficiency visualization method provides a two
	order of magnitude speedup in selecting good rewards, compared to
	running a full simulation. In addition, this method facilitates the
	design and analysis of new rewards tailored to the observational
	limitations of the domain, providing rewards that combine the best
	properties of traditional rewards.},
  bib2html_pubtype = {Journal Articles},
  bib2html_rescat = {Reinforcement Learning, Multiagent Systems}
}

@CONFERENCE{Bertsimas,
  author = {Bertsimas, D. and Patterson, S.S.},
  title = {The Air Traffic Flow Management Problem with Enroute Capacities},
  booktitle = {May-June 1998, pp. 406–422},
  year = {1998},
  owner = {Will},
  timestamp = {2012.10.09}
}

@ARTICLE{FACET,
  author = {Bilimoria, K. D., B. Sridhar, G. B. Chatterji, K. S. Shethand, and
	S. R. Grabbe},
  title = {FACET: Future ATM Concepts Evaluation Tool},
  journal = {Air Traffc Control Quarterly},
  year = {2001},
  volume = {9},
  pages = {1},
  owner = {Will},
  timestamp = {2012.10.12}
}

@CONFERENCE{Agglomerative,
  author = {William H.E. Day and Herbert Edelsbrunner},
  title = {Efficient Algorithms for Agglomerative Hierarchical Clustering Methods},
  booktitle = {Journal of Classification},
  year = {1984},
  number = {1},
  series = {7-24},
  owner = {Will},
  timestamp = {2012.10.12}
}

@ARTICLE{Hardin,
  author = {G. Hardin},
  title = {The tragedy of the commons},
  journal = {Science},
  year = {December 1968},
  volume = {162},
  pages = {1243–1248},
  owner = {Will},
  timestamp = {2012.10.09}
}

@UNPUBLISHED{faa05,
  author = {FAA OPSNET},
  title = {{US} {D}epartment of {T}ransportation website},
  note = {(http://www.faa.gov/data\_statistics/)},
  year = {2011}
}

@MISC{Nobody06,
  author = {Nobody Jr},
  title = {My Article},
  year = {2006}
}

@INPROCEEDINGS{Junges:2008:EPD:1402298.1402308,
  author = {Junges, Robert and Bazzan, Ana L. C.},
  title = {Evaluating the performance of DCOP algorithms in a real world, dynamic
	problem},
  booktitle = {Proceedings of the 7th international joint conference on Autonomous
	agents and multiagent systems - Volume 2},
  year = {2008},
  series = {AAMAS '08},
  pages = {599--606},
  address = {Richland, SC},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  acmid = {1402308},
  isbn = {978-0-9817381-1-6},
  keywords = {coordination, distributed constraint optimization, traffic control},
  location = {Estoril, Portugal},
  numpages = {8},
  url = {http://dl.acm.org/citation.cfm?id=1402298.1402308}
}

@INPROCEEDINGS{5509316,
  author = {Kaminka, G.A. and Erusalimchik, D. and Kraus, S.},
  title = {Adaptive multi-robot coordination: A game-theoretic perspective},
  booktitle = {Robotics and Automation (ICRA), 2010 IEEE International Conference
	on},
  year = {2010},
  doi = {10.1109/ROBOT.2010.5509316},
  issn = {1050-4729},
  keywords = {adaptive multirobot coordination;coordination algorithm selection;effectiveness
	index;game-theoretic perspective;matrix games;multirobot foraging;multirobot
	learning;reinforcement-learning approach;resource-spending velocity;reward
	function;spatial coordination;game theory;learning systems;multi-robot
	systems;robot dynamics;}
}

@ARTICLE{Kok:2006:CMR:1248547.1248612,
  author = {Kok, Jelle R. and Vlassis, Nikos},
  title = {Collaborative Multiagent Reinforcement Learning by Payoff Propagation},
  journal = {J. Mach. Learn. Res.},
  year = {2006},
  volume = {7},
  pages = {1789--1828},
  month = dec,
  acmid = {1248612},
  issn = {1532-4435},
  issue_date = {12/1/2006},
  numpages = {40},
  publisher = {JMLR.org},
  url = {http://dl.acm.org/citation.cfm?id=1248547.1248612}
}

@INPROCEEDINGS{Panait,
  author = {Liviu Panait, Keith Sullivan, and Sean Luke.},
  title = {Lenience towards teammates helps in cooperative multiagent learning.},
  booktitle = {Proceedings of the Fifth International Joint Conference on Autonomous
	Agents and Multi Agent Systems},
  year = {2006},
  owner = {Will},
  timestamp = {2012.10.10}
}

@ARTICLE{Modi:2005:AAD:1120120.1120127,
  author = {Modi, Pragnesh Jay and Shen, Wei-Min and Tambe, Milind and Yokoo,
	Makoto},
  title = {Adopt: asynchronous distributed constraint optimization with quality
	guarantees},
  journal = {Artif. Intell.},
  year = {2005},
  volume = {161},
  pages = {149--180},
  number = {1-2},
  month = jan,
  acmid = {1120127},
  address = {Essex, UK},
  doi = {10.1016/j.artint.2004.09.003},
  issn = {0004-3702},
  issue_date = {January 2005},
  keywords = {constraints, distributed optimization, multiagent systems},
  numpages = {32},
  publisher = {Elsevier Science Publishers Ltd.},
  url = {http://dx.doi.org/10.1016/j.artint.2004.09.003}
}

@INPROCEEDINGS{Rios,
  author = {Rios, J. and Lohn, J.},
  title = {A Comparison of Optimization Approaches for Nationwide Traffic Flow
	Management},
  booktitle = {Proceedings of the AIAA Guidance, Navigation, and Control Conference,
	Chicago, Illinois},
  year = {2009}
}

@ARTICLE{Sridhar,
  author = {Sridhar, B. and Grabbe, S.R. and Mukherjee, A.},
  title = {Modeling and Optimization in Traffic Flow Management},
  journal = {Proceedings of the IEEE},
  year = {2008},
  volume = {96},
  pages = {2060 -2080},
  number = {12},
  month = {dec. },
  doi = {10.1109/JPROC.2008.2006141},
  issn = {0018-9219},
  keywords = {air traffic control;airport;decision theory;human factor;operations
	research;optimization;software engineering;traffic flow management;air
	traffic control;airports;decision theory;optimisation;}
}

@INPROCEEDINGS{6095996, 
author={Agogino, A. and Rios, J.}, 
booktitle={Digital Avionics Systems Conference (DASC), 2011 IEEE/AIAA 30th}, title={Robustness of two air traffic scheduling approaches to departure uncertainty}, 
year={2011}, 
pages={2C6-1-2C6-8}, 
keywords={air traffic control;evolutionary computation;linear programming;nonlinear programming;robust control;uncertain systems;air traffic scheduling;binary programming approach;departure uncertainty;fast-learning evolutionary algorithm;large scale air traffic flow problem;linear programming method;nonlinear evolutionary algorithm-based optimization technique;Aircraft;Airports;Biological cells;Delay;Evolutionary computation;Schedules;Uncertainty}, 
doi={10.1109/DASC.2011.6095996}, 
ISSN={2155-7195},}

@ARTICLE{664154,
  author = {Tomlin, C. and Pappas, G.J. and Sastry, S.},
  title = {Conflict resolution for air traffic management: a study in multiagent
	hybrid systems},
  journal = {Automatic Control, IEEE Transactions on},
  year = {1998},
  volume = {43},
  pages = {509 -521},
  number = {4},
  month = {apr},
  doi = {10.1109/9.664154},
  issn = {0018-9286},
  keywords = {ATC;air traffic management;aircraft control;distributed control system;multiagent
	hybrid systems;trajectory conflict resolution;verification;aerodynamics;air
	traffic control;aircraft control;cooperative systems;distributed
	control;}
}

@INPROCEEDINGS{Coordination,
  author = {N. Vlassis and R. Elhorst and J. R. Kok},
  title = {Anytime algorithms for multiagent decision making using coordination
	graphs},
  booktitle = {International Conference on Systems, Man and Cybernetics},
  year = {2004},
  owner = {Will},
  timestamp = {2012.10.10}
}

@ARTICLE{tumer-wolpert_jair02,
  author = {D. H. Wolpert and K. Tumer},
  title = {Collective Intelligence, Data Routing and {B}raess' Paradox},
  journal = {Journal of Artificial Intelligence Research},
  year = {2002},
  volume = {16},
  pages = {359-387},
  abstract = {We consider the problem of designing the the utility functions of
	the utility-maximizing agents in a multi-agent system (MAS) so that
	they work synergistically to maximize a global utility. The particular
	problem domain we explore is the control of network routing by placing
	agents on all the routers in the network. Conventional approaches
	to this task have the agents all use the Ideal Shortest Path routing
	Algorithm (ISPA). We demonstrate that in many cases, due to the side-effects
	of one agent's actions on another agent's performance, having agents
	use ISPA's is suboptimal as far as global aggregate cost is concerned,
	even when they are only used to route infinitesimally small amounts
	of traffic. The utility functions of the individual agents are not
	"aligned" with the global utility, intuitively speaking. As a particular
	example of this we present an instance of Braess' paradox in which
	adding new links to a network whose agents all use the ISPA results
	in a <em>decrease</em> in overall throughput. We also demonstrate
	that load-balancing, in which the agents' decisions are collectively
	made to optimize the global cost incurred by all traffic <em>currently</em>
	being routed, is suboptimal as far as global cost <em>averaged across
	time</em> is concerned. This is also due to "side-effects", in this
	case of current routing decision on future traffic. The mathematics
	of Collective Intelligence (COIN) is concerned precisely with the
	issue of avoiding such deleterious side-effects in multi-agent systems,
	both over time and space. We present key concepts from that mathematics
	and use them to derive an algorithm whose ideal version should have
	better performance than that of having all agents use the ISPA, even
	in the infinitesimal limit. We present experiments verifying this,
	and also showing that a machine-learning-based version of this COIN
	algorithm in which costs are only imprecisely estimated via empirical
	means (a version potentially applicable in the real world) also outperforms
	the ISPA, despite having access to less information than does the
	ISPA. In particular, this COIN algorithm almost always avoids Braess'
	paradox.},
  bib2html_pubtype = {Journal Articles},
  bib2html_rescat = {Multiagent Systems, Collectives, Traffic and Transportation}
}


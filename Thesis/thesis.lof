\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Delay and congestion with varying $w$, the weight on congestion. No matter the weight, the learning algorithm will not remove congestion while attempting to keep delay low. Additionally the cost to delay for when removing congestion is not a 1:1 mapping. A removal of 10,000 congestion adds 70,000 minutes of delay}}{24}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Evaluation using the greedy scheduler}}{26}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Using the system-level performance as a reward does not work well in this large multiagent system. The difference reward was able to lower congestion much more, but could not manage to also reduce delay. Note that these are best performing experiments for the difference reward and system-level reward.}}{42}
\contentsline {figure}{\numberline {5.2}{\ignorespaces The highest level of partitioning for the system-level reward (G) is displayed here and compared with zero partitioning and the greedy scheduler. The system-level reward performed worse with fewer partitions, but still better than zero partitioning. Even though partitioning performed better than zero partitioning, the system-level reward could not come close to beating the greedy scheduler. Using this learning approach, the system-level reward performance could never become better than the greedy scheduler.}}{44}
\contentsline {figure}{\numberline {5.3}{\ignorespaces A closer look at the difference reward performance using the smaller number of partitions shows a 37\% improvement over the greedy scheduling solution.}}{45}
\contentsline {figure}{\numberline {5.4}{\ignorespaces As the number of partitions decrease, the agents receive less information about the environment, and performance decreases. In this domain, 2 and 3 partitions work equally well as the difference reward, but with 6x faster simulation rate.}}{49}
\contentsline {figure}{\numberline {5.5}{\ignorespaces This graph represents the scaled value of different performance metrics. For example, a scaled value of .50 for the converged performance represents that this is 50\% of the best converged performance. As self-similarity decreases, the performance and average time taken per learning step decreases. This trend rate begins slow, but increases dramatically once self-similarity is less than 67\%. In this domain, this level of self-similarity is an important metric to stay above while partitioning.}}{50}
\contentsline {figure}{\numberline {5.6}{\ignorespaces As the number of partitions decreases, performance improves while time complexity increases. Note that a reward independent partitioning using RUBI includes 61 partitions. }}{52}
\contentsline {figure}{\numberline {5.7}{\ignorespaces As the self-similarity increases, final performance and time taken per learning step increases. Note that final performance is a 6th degree polynomial trend line with $R^2 = .95$}}{54}
\contentsline {figure}{\numberline {5.8}{\ignorespaces Partitions formed with RUBI had higher self-similarity than using domain-based partitioning. This leads to higher quality learning with respect to each partition.}}{55}
\contentsline {figure}{\numberline {5.9}{\ignorespaces The final performance of RUBI partitions compared to domain-based partitions. Initially domain-based partitions perform better than RUBI, with RUBI performing better with a smaller number of partitions. We see that this is not a good performance metric, as it does not take into account individual partition sizes. Note that the a 6th degree polynomial was used in creating this graph with an $R^2$ value of $.95$ for partitioning with RUBI and $.92$ for domain-based partitioning.}}{58}
\contentsline {figure}{\numberline {5.10}{\ignorespaces Initially, domain-based partitioning has a larger average size of partitions, leading to a higher initial performance. With a smaller number of partitions, RUBI partitioning had a larger size of partitions. Note that when all partitions are reward independent, domain-based partitioning had only a few number of very large partitions. RUBI partitioning on the other hand included a much smaller average size, and many more partitions. }}{59}
\contentsline {figure}{\numberline {5.11}{\ignorespaces When comparing individual partition size averages to performance, RUBI partitions perform much better than domain specific partitions with respect to average partition size and final performance.}}{60}
\addvspace {10\p@ }

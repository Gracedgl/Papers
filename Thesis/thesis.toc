\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {chapter}{\numberline {2}Background}{5}
\contentsline {section}{\numberline {2.1}Multiagent Systems}{5}
\contentsline {subsection}{\numberline {2.1.1}Reinforcement Learning}{5}
\contentsline {subsection}{\numberline {2.1.2}Multiagent Learning}{7}
\contentsline {subsection}{\numberline {2.1.3}Reward Shaping for Coordination}{8}
\contentsline {subsection}{\numberline {2.1.4}Agent Coordination}{9}
\contentsline {section}{\numberline {2.2}Agent Partitioning}{10}
\contentsline {subsection}{\numberline {2.2.1}Clustering algorithms}{10}
\contentsline {subsection}{\numberline {2.2.2}Hierarchical Agglomerative Clustering}{11}
\contentsline {section}{\numberline {2.3}Related Work}{12}
\contentsline {subsection}{\numberline {2.3.1}Air Traffic Flow Management Problem}{13}
\contentsline {subsection}{\numberline {2.3.2}Constraint Optimization}{13}
\contentsline {subsection}{\numberline {2.3.3}Agent Partitioning}{14}
\contentsline {section}{\numberline {2.4}Domains}{15}
\contentsline {subsection}{\numberline {2.4.1}Heterogeneous Bar Problem}{15}
\contentsline {subsection}{\numberline {2.4.2}Air Traffic Flow Management Problem}{17}
\contentsline {chapter}{\numberline {3}Approach}{18}
\contentsline {section}{\numberline {3.1}Agent Definition}{18}
\contentsline {section}{\numberline {3.2}Agent Learning}{20}
\contentsline {section}{\numberline {3.3}Reward Structures}{21}
\contentsline {subsection}{\numberline {3.3.1}Assigning the System-Level reward}{21}
\contentsline {subsection}{\numberline {3.3.2}Applying the Difference Reward}{22}
\contentsline {section}{\numberline {3.4}Soft Constraint Application}{23}
\contentsline {section}{\numberline {3.5}Hard Constraint Optimization}{25}
\contentsline {section}{\numberline {3.6}Agent Partitioning}{26}
\contentsline {subsection}{\numberline {3.6.1}Computational Complexity}{28}
\contentsline {section}{\numberline {3.7}Simulator Characteristics}{29}
\contentsline {chapter}{\numberline {4}Partitioning Agents}{31}
\contentsline {section}{\numberline {4.1}Domain-Based Partitioning}{31}
\contentsline {section}{\numberline {4.2}Reward/Utility Based Impact Algorithm}{32}
\contentsline {subsection}{\numberline {4.2.1}Implementation of RUBI}{33}
\contentsline {subsection}{\numberline {4.2.2}Impact Calculation}{34}
\contentsline {subsection}{\numberline {4.2.3}Simulation}{35}
\contentsline {subsection}{\numberline {4.2.4}Computational Cost}{36}
\contentsline {subsection}{\numberline {4.2.5}Benefits of RUBI}{37}
\contentsline {chapter}{\numberline {5}Experimental Results}{39}
\contentsline {section}{\numberline {5.1}Hard Constraint Optimization with Domain-Based Partitioning}{39}
\contentsline {subsection}{\numberline {5.1.1}Learning with Soft Constraints}{40}
\contentsline {subsection}{\numberline {5.1.2}Learning with Hard Constraints}{41}
\contentsline {subsection}{\numberline {5.1.3}Partition Comparisons for Hard Constraints}{46}
\contentsline {section}{\numberline {5.2}Hard Constraint Optimization using RUBI}{47}
\contentsline {subsection}{\numberline {5.2.1}Heterogeneous Bar Problem}{47}
\contentsline {subsection}{\numberline {5.2.2}ATFMP}{51}
\contentsline {subsubsection}{\numberline {5.2.2.1}RUBI Performance in the ATFMP}{51}
\contentsline {section}{\numberline {5.3}Comparison Between RUBI and Domain-Based Partitioning}{53}
\contentsline {chapter}{\numberline {6}Conclusion}{61}
\contentsline {section}{\numberline {6.1}Future Work}{62}
\contentsline {chapter}{Bibliography}{62}
